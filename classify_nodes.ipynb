{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import first_block_of_day, last_block_of_day, exeSQL\n",
    "import os, pickle\n",
    "\n",
    "date_start = '2015-10-01'\n",
    "date_end = '2015-12-31'\n",
    "block_start = first_block_of_day(int(date_start[:4]), int(date_start[5:7]), int(date_start[8:10]))\n",
    "block_end = last_block_of_day(int(date_end[:4]), int(date_end[5:7]), int(date_end[8:10]))\n",
    "\n",
    "action_table_nointernal_name = \"action_20151001_20151231_nointernal\"\n",
    "action_table_nointernal_noreward_name = \"action_20151001_20151231_nointernal_noreward\"\n",
    "feature_table_name = \"cluster_features_20151001_20151231\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch addrs which solve pow algorithm\n",
    "def fetch_addrs_set_solving_pow():\n",
    "    if os.path.isfile('addrs_set_solving_pow_2015_4.pkl'):\n",
    "        with open('addrs_set_solving_pow_2015_4.pkl', 'rb') as f:\n",
    "            addrs_solving_pow_set = pickle.load(f)\n",
    "    else:\n",
    "        fetch_addrs_solving_pow_sql = \"\"\"select target from {} where directive='reward-block'\"\"\".format(action_table_name)\n",
    "        addrs_solving_pow_sql_result = exeSQL(fetch_addrs_solving_pow_sql)\n",
    "        addrs_solving_pow_set = set([r[0] for r in addrs_solving_pow_sql_result])\n",
    "        with open('addrs_set_solving_pow_2015_4.pkl', 'wb') as f:\n",
    "            pickle.dump(addrs_solving_pow_set, f)\n",
    "    return addrs_solving_pow_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def fetch_total_addr():\n",
    "    if os.path.isfile('total_addr_set_20151001_20151231.pkl'):\n",
    "        with open('total_addr_set_20151001_20151231.pkl', 'rb') as f:\n",
    "            total_addr_set = pickle.load(f)\n",
    "    else:\n",
    "        source_set = fetchAddressSet('source')\n",
    "        target_set = fetchAddressSet('target')\n",
    "        total_addr_set = source_set.union(target_set)\n",
    "        with open('total_addr_set_20151001_20151231.pkl', 'wb') as f:\n",
    "            pickle.dump(total_addr_set, f)\n",
    "    return total_addr_set\n",
    "\n",
    "total_addr_set = fetch_total_addr()\n",
    "# addrs_mark = {}\n",
    "# for addr in total_addr_set:\n",
    "#     addrs_mark[addr] = []\n",
    "print ('0x2a65aca4d5fc5b5c859090a6c34d164135398226' in total_addr_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark possible mining pools as 1\n",
    "def mark_possible_mining_pool_condition1():\n",
    "    mark_num = 1\n",
    "    addrs_pool_sql = \"\"\"select address from {} where out_num >= 8 and out_dec_places >= 8 \n",
    "            and out_ethers >= 0.5 and out_addrs_set_len >= 3\"\"\".format(feature_table_name)\n",
    "    addrs_pool_sql_result = exeSQL(addrs_pool_sql)\n",
    "    count_dict = {}\n",
    "    addrs_pool_list = [r[0] for r in addrs_pool_sql_result]\n",
    "    addrs_pool_list_set = set(addrs_pool_list)\n",
    "    return addrs_pool_list_set\n",
    "#     for r in addrs_pool_sql_result:\n",
    "#         if r[0] not in count_dict:\n",
    "#             count_dict[r[0]] = 1\n",
    "#         else:\n",
    "#             count_dict[r[0]] += 1\n",
    "#     return count_dict\n",
    "    \n",
    "#     for r in addrs_pool_sql_result:\n",
    "#         addrs_mark[r[0]].append(mark_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark possible cooperative miners as 2\n",
    "def mark_possible_co_miners():\n",
    "    mark_num = 2\n",
    "    addrs_co_miners_sql = \"\"\"select address from {} where in_dec_places >= 8\"\"\".format(feature_table_name)\n",
    "    addrs_co_miners_sql_result = exeSQL(addrs_co_miners_sql)\n",
    "    for r in addrs_co_miners_sql_result:\n",
    "        addrs_mark[r[0]].append(mark_num)\n",
    "    return [r[0] for r in addrs_co_miners_sql_result]\n",
    "co_miners_2 = mark_possible_co_miners()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0x9c56158cb63f026e7f80e2ba0f0d510dd9bbaf4b', '0xe01debe6af51809320e16f9ff1cb0be8dd666a0c', '0xe01debe6af51809320e16f9ff1cb0be8dd666a0c', '0xd6cbc00b3ecff6e48a1106feaf62f77c4f52e465', '0x375bbb5f739f20f8cec43d86b787c8a1ec4576da', '0x5efd26b739a4398bf9b3b9356a5119bcc4ad543a', '0x5efd26b739a4398bf9b3b9356a5119bcc4ad543a', '0x5efd26b739a4398bf9b3b9356a5119bcc4ad543a', '0x5efd26b739a4398bf9b3b9356a5119bcc4ad543a', '0x5efd26b739a4398bf9b3b9356a5119bcc4ad543a']\n"
     ]
    }
   ],
   "source": [
    "print (co_miners_2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark possible cooperative miners as 3\n",
    "def mark_possible_co_miners():\n",
    "    mark_num = 3\n",
    "    addrs_co_miners_sql = \"\"\"select address from {} where abs((in_ethers - out_ethers)/in_ethers) < 0.1\"\"\".format(feature_table_name)\n",
    "    addrs_co_miners_sql_result = exeSQL(addrs_co_miners_sql)\n",
    "    for r in addrs_co_miners_sql_result:\n",
    "        addrs_mark[r[0]].append(mark_num)\n",
    "    return [r[0] for r in addrs_pool_sql_result]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0x2a65aca4d5fc5b5c859090a6c34d164135398226', '0xf8b483dba2c3b7176a3da549ad41a48bb3121069', '0x1dcb8d1f0fcc8cbc8c2d76528e877f915e299fbe', '0x22a0fbf89ad1362d74f626436d8c4fc6dc4f0679', '0x52bc44d5378309ee2abf1539bf71de1b7d7be3b5', '0xd1e56c2e765180aa0371928fd4d1e41fbcda34d4', '0x68795c4aa09d6f4ed3e5deddf8c2ad3049a601da', '0x4bb96091ee9d802ed039c4d1a5f6216f90f81b01', '0x9d551f41fed6fc27b719777c224dfecce170004d', '0xa027231f42c80ca4125b5cb962a21cd4f812e88f', '0x63a9975ba31b0b9626b34300f7f627147df1f526', '0xa5a5d0bcf280c83eae64e846033fc835afc8961e'}\n"
     ]
    }
   ],
   "source": [
    "def fetch_mining_pools():\n",
    "    # Fetch addrs with massive out transactsions\n",
    "    def fetch_addrs_massive_out_txs():\n",
    "        addrs_massive_out_txs_sql = \"\"\" select source, ct from (select source, count(target) as ct from\n",
    "                {} group by source) A where ct > 100\"\"\".format(action_table_nointernal_noreward_name)\n",
    "        addrs_massive_out_txs_sql_result = exeSQL(addrs_massive_out_txs_sql)\n",
    "        addrs_massive_out_txs_set = set([r[0] for r in addrs_massive_out_txs_sql_result])\n",
    "        return addrs_massive_out_txs_set\n",
    "    \n",
    "    # Fetch addrs with multiple different out addrs\n",
    "    def fetch_addrs_multiple_outaddrs_txs():\n",
    "        addrs_multiple_outaddrs_txs_sql = \"\"\" select source, dt from (select source, count(distinct(target)) as dt from\n",
    "                {} group by source) A where dt > 15\"\"\".format(action_table_nointernal_noreward_name)\n",
    "        addrs_multiple_outaddrs_txs_sql_result = exeSQL(addrs_multiple_outaddrs_txs_sql)\n",
    "        addrs_multiple_outaddrs_txs_set = set([r[0] for r in addrs_multiple_outaddrs_txs_sql_result])\n",
    "        return addrs_multiple_outaddrs_txs_set\n",
    "    \n",
    "    if os.path.isfile('pools_set_2015_4.pkl'):\n",
    "        with open('pools_set_2015_4.pkl', 'rb') as f:\n",
    "            pools_set = pickle.load(f)\n",
    "    else:\n",
    "        addrs_multiple_outaddrs_txs_set = fetch_addrs_multiple_outaddrs_txs()\n",
    "        addrs_massive_out_txs_set = fetch_addrs_massive_out_txs()\n",
    "        addrs_solving_pow_set = fetch_addrs_set_solving_pow()\n",
    "        pools_set = addrs_massive_out_txs_set.intersection(addrs_solving_pow_set).intersection(addrs_multiple_outaddrs_txs_set)\n",
    "\n",
    "        # Filter out the addrs with massive tiny out transactions\n",
    "        pools_set.remove('0xcf684dfb8304729355b58315e8019b1aa2ad1bac')\n",
    "        \n",
    "        with open('pools_set_2015_4.pkl', 'wb') as f:\n",
    "            pickle.dump(pools_set, f)\n",
    "        \n",
    "    return pools_set\n",
    "\n",
    "print (fetch_mining_pools())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_standalone_miners():\n",
    "    if os.path.isfile('sminers_set_2015_4.pkl'):\n",
    "        with open('sminers_set_2015_4.pkl', 'rb') as f:\n",
    "            standalone_miners_set = pickle.load(f)\n",
    "    else:\n",
    "        addrs_solving_pow_set = fetch_addrs_set_solving_pow()\n",
    "        pools_set = fetch_mining_pools()\n",
    "        standalone_miners_set = addrs_solving_pow_set.difference(pools_set)\n",
    "        with open('sminers_set_2015_4.pkl', 'wb') as f:\n",
    "            pickle.dump(standalone_miners_set, f)\n",
    "    return standalone_miners_set\n",
    "\n",
    "standalone_miners_set = fetch_standalone_miners()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605\n"
     ]
    }
   ],
   "source": [
    "print (len(standalone_miners_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_cooperative_miners():\n",
    "    if os.path.isfile('cominers_set_2015_4.pkl'):\n",
    "        with open('cominers_set_2015_4.pkl', 'rb') as f:\n",
    "            cooperative_miners_set = pickle.load(f)\n",
    "    else:\n",
    "        cooperative_miners_set = set()\n",
    "        pools_set = fetch_mining_pools()\n",
    "        for pool in pools_set:\n",
    "            fetch_recipients_from_pools_sql = \"\"\"select target from {} where source= '{}'\n",
    "                    \"\"\".format(action_table_nointernal_noreward_name, pool)\n",
    "            fetch_recipients_result = exeSQL(fetch_recipients_from_pools_sql)\n",
    "            for r in fetch_recipients_result:\n",
    "                cooperative_miners_set.add(r[0])\n",
    "        with open('cominers_set_2015_4.pkl', 'wb') as f:\n",
    "            pickle.dump(cooperative_miners_set, f)\n",
    "    return cooperative_miners_set\n",
    "\n",
    "co_miners_set = fetch_cooperative_miners()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3910\n"
     ]
    }
   ],
   "source": [
    "print (len(co_miners))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_exchanges():\n",
    "    if os.path.isfile('exchanges_set_2015_4.pkl'):\n",
    "        with open('exchanges_set_2015_4.pkl', 'rb') as f:\n",
    "            exchanges_set = pickle.load(f)\n",
    "    else:\n",
    "    \n",
    "        # Fetch addrs with massive out transactsions, recipients are not smart contracts, recipients are diverse\n",
    "        def fetch_addrs_massive_out_txs():\n",
    "            addrs_massive_out_txs_sql = \"\"\" select source, cdt from (select source, count(distinct(target))\n",
    "                as cdt from {} left join account on \n",
    "                {}.target=account.address where \n",
    "                account.kind='normal' group by source) A where cdt > 50\"\"\".format(action_table_nointernal_noreward_name,\n",
    "                                                                                 action_table_nointernal_noreward_name)\n",
    "            addrs_massive_out_txs_sql_result = exeSQL(addrs_massive_out_txs_sql)\n",
    "            addrs_massive_out_txs_set = set([r[0] for r in addrs_massive_out_txs_sql_result])\n",
    "            return addrs_massive_out_txs_set\n",
    "        # Fetch addrs with massive out transactsions，amounts are diverse\n",
    "        def fetch_addrs_massive_out_amount_txs():\n",
    "            addrs_massive_amount_txs_sql = \"\"\" select source, cda from (select source, count(distinct(amount))\n",
    "                as cda from {} group by source) A where cda > 50\"\"\".format(action_table_nointernal_noreward_name)\n",
    "            addrs_massive_amount_txs_sql_result = exeSQL(addrs_massive_amount_txs_sql)\n",
    "            addrs_massive_amount_txs_set = set([r[0] for r in addrs_massive_amount_txs_sql_result])\n",
    "            return addrs_massive_amount_txs_set\n",
    "\n",
    "        # Fetch addrs with massive in transactsions, recipients are not smart contracts, recipients are diverse\n",
    "        def fetch_addrs_massive_in_txs():\n",
    "            addrs_massive_in_txs_sql = \"\"\" select target, cds from (select target, count(distinct(source))\n",
    "                as cds from {} left join account on \n",
    "                {}.source=account.address where \n",
    "                account.kind='normal' group by target) A where cds > 50\"\"\".format(action_table_nointernal_noreward_name,\n",
    "                                                                                 action_table_nointernal_noreward_name)\n",
    "            addrs_massive_in_txs_sql_result = exeSQL(addrs_massive_in_txs_sql)\n",
    "            addrs_massive_in_txs_set = set([r[0] for r in addrs_massive_in_txs_sql_result])\n",
    "            return addrs_massive_in_txs_set\n",
    "\n",
    "        # Fetch addrs with massive in transactsions，amounts are diverse\n",
    "        def fetch_addrs_massive_in_amount_txs():\n",
    "            addrs_massive_amount_txs_sql = \"\"\" select target, cda from (select target, count(distinct(amount))\n",
    "                as cda from {} group by target) A where cda > 50\"\"\".format(action_table_nointernal_noreward_name)\n",
    "            addrs_massive_amount_txs_sql_result = exeSQL(addrs_massive_amount_txs_sql)\n",
    "            addrs_massive_amount_txs_set = set([r[0] for r in addrs_massive_amount_txs_sql_result])\n",
    "            return addrs_massive_amount_txs_set\n",
    "\n",
    "        addrs_massive_out_txs_set = fetch_addrs_massive_out_txs()\n",
    "        addrs_massive_amount_out_txs_set = fetch_addrs_massive_out_amount_txs()\n",
    "        exchanges_out_set = addrs_massive_out_txs_set.intersection(addrs_massive_amount_out_txs_set)\n",
    "\n",
    "        addrs_massive_in_txs_set = fetch_addrs_massive_in_txs()\n",
    "        addrs_massive_amount_in_txs_set = fetch_addrs_massive_in_amount_txs()\n",
    "        exchanges_in_set = addrs_massive_in_txs_set.intersection(addrs_massive_amount_in_txs_set)\n",
    "\n",
    "        pools_set = fetch_mining_pools()\n",
    "        exchanges_set = exchanges_out_set.union(exchanges_in_set).difference(pools_set)\n",
    "        \n",
    "        with open('exchanges_set_2015_4.pkl', 'wb') as f:\n",
    "            pickle.dump(exchanges_set, f)\n",
    "        \n",
    "    return exchanges_set\n",
    "exchanges = fetch_exchanges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "print (len(exchanges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_addrs_massive_out_txs():\n",
    "    addrs_massive_out_txs_sql = \"\"\" select source, cdt from (select source, count(distinct(target))\n",
    "        as cdt from {} left join account on \n",
    "        {}.target=account.address where \n",
    "        account.kind='normal' group by source) A where cdt > 50\"\"\".format(action_table_nointernal_noreward_name,\n",
    "                                                                         action_table_nointernal_noreward_name)\n",
    "    addrs_massive_out_txs_sql_result = exeSQL(addrs_massive_out_txs_sql)\n",
    "    addrs_massive_out_txs_set = set([r[0] for r in addrs_massive_out_txs_sql_result])\n",
    "    return addrs_massive_out_txs_set\n",
    "\n",
    "addrs_massive_out_txs_set = fetch_addrs_massive_out_txs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "print (len(addrs_massive_out_txs_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1081\n"
     ]
    }
   ],
   "source": [
    "def fetch_addrs_massive_amount_txs():\n",
    "    addrs_massive_amount_txs_sql = \"\"\" select source, cda from (select source, count(distinct(amount))\n",
    "        as cda from {} group by source) A where cda > 50\"\"\".format(action_table_nointernal_noreward_name)\n",
    "    addrs_massive_amount_txs_sql_result = exeSQL(addrs_massive_amount_txs_sql)\n",
    "    addrs_massive_amount_txs_set = set([r[0] for r in addrs_massive_amount_txs_sql_result])\n",
    "    return addrs_massive_amount_txs_set\n",
    "\n",
    "addrs_massive_amount_txs_set = fetch_addrs_massive_amount_txs()\n",
    "print (len(addrs_massive_amount_txs_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "addrs_union_set = addrs_massive_out_txs_set.intersection(addrs_massive_amount_txs_set)\n",
    "print (len(addrs_union_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
